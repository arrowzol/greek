#!/usr/local/bin/python3

import go_greek as g
import sys

DO_DECLS = "3"
DO_DECLS = "12"

_show_errr_dbg = "-GEW"

def_art_base = (
# singular --------------
#   mas     fem     neu
    "ο",    "η",    "το",       # nominative
    "του",  "της",  "του",      # genative
    "τω",   "τη",   "τω",       # dative
    "τον",  "την",  "το",       # accusative
# plural ----------------
#   mas     fem     neu
    "οι",   "αι",   "τα",       # nominative
    "των",  "των",  "των",      # genative
    "τοις", "ταις", "τοις",     # dative
    "τους", "τας",  "τα")       # accusative

def_art_to_indexes = {}
for def_art, index in zip(def_art_base, range(2*3*4)):
    if not def_art in def_art_to_indexes:
        def_art_to_indexes[def_art] = []
    def_art_to_indexes[def_art].append(index)


def read_words(files, show_ch_vs=False):
    """
    Read greek words from a list of files
    """
    for fn in files:
        fh = open(fn)

        ch = '0'
        for line in fh:
            if line.startswith("CH "):
                ch = line[3:].rstrip()
                continue

            tail = 0;
            in_num = False
            for head in range(len(line)):
                let = line[head]
                if let >= "0" and let <= "9":
                    if not in_num:
                        if head > tail:
                            yield line[tail:head]
                        tail = head
                        in_num = True
                    continue

                if in_num:
                    in_num = False
                    if show_ch_vs:
                        yield ch + ":" + line[tail:head]
                    tail = head

                if not let in g._all_greek_letter_set:
                    if head > tail:
                        yield line[tail:head]
                    if let != " ":
                        yield let
                    tail = head+1
            if tail > head:
                yield line[tail:]
            yield "EOL"
        fh.close()

_3_mf = [g._noun_stems["3"]["-"][num][cas]
    for num in "SP"
    for cas in "NGDA"
    ]

# look out for NS and DP, their endings start with a consonant and many changes
_3_mf[0] = "-"
_3_mf[4+2] = "-"


class OneNoun:
    """
    Collect nouns with the same root
    """

    def __init__(self, root_word):
        self.root_word = root_word
        self.unique_words = set()
        self.index_to_word = ["-"]*(2*3*4)
        self.index_to_hits = [0]*(2*3*4)

        self.all_word_hits = 0

        # cwp = collision word pair
        self.cwp_to_base_collision_count = {}
        self.cwp_to_morph_collision_count = {}

    def add_word(self, def_art, word):
        b_word = g.base_word(word)
        self.all_word_hits += 1
        self.unique_words.add(b_word)
        for i in def_art_to_indexes[def_art]:
            self.index_to_hits[i] += 1
            if self.index_to_word[i] == "-":
                self.index_to_word[i] = word
            else:
                if self.index_to_word[i] != word:
                    if self.index_to_word[i] > word:
                        key = (self.index_to_word[i], word)
                    else:
                        key = (word, self.index_to_word[i])
                    if b_word == g.base_word(self.index_to_word[i]):
                        self.cwp_to_morph_collision_count[key] = \
                            self.cwp_to_morph_collision_count.get(key, 0) + 1
                    else:
                        self.cwp_to_base_collision_count[key] = \
                            self.cwp_to_base_collision_count.get(key, 0) + 1

    @staticmethod
    def _idx(sp, ngda, mfn):
        if type(sp) == str:
            sp = "SP".index(sp)
        if type(ngda) == str:
            ngda = "NGADV".index(ngda)
        if type(mfn) == str:
            mfn = "MFN".index(mfn)
        return (sp*4 + ngda)*3 + mfn

    def derive_roots(self):
        mas_uniq_word_count = len(set((
            g.base_word(word)
            for word in (self.index_to_word[OneNoun._idx(0, i, 0)] for i in range(8))
            if word != "-")))
        mas_case_count = sum((
            1
            for word in (self.index_to_word[OneNoun._idx(0, i, 0)] for i in range(8))
            if word != "-"))
        mas_count = sum((self.index_to_hits[OneNoun._idx(0, i, 0)] for i in [
            0,                      3,
            0 +4,                   3 +4]))

        fem_uniq_word_count = len(set((
            g.base_word(word)
            for word in (self.index_to_word[OneNoun._idx(0, i, 1)] for i in range(8))
            if word != "-")))
        fem_case_count = sum((
            1
            for word in (self.index_to_word[OneNoun._idx(0, i, 1)] for i in range(8))
            if word != "-"))
        fem_count = sum((self.index_to_hits[OneNoun._idx(0, i, 1)] for i in [
            0,      1,      2,      3,
            0 +4,           2 +4,   3 +4]))

        roots = []

        word_f = word_m = decl_m = gen_m = decl_f = gen_f = "-"

        if fem_count > 0 and fem_case_count >= 2:
            # TODO: add P to the list below AND ...
            # TODO: undo α η swap when looking for the root, when (gen == "F", cas in "GD", usually num == "P"), _idx
            count_and_word_list = [
                (self.index_to_hits[0*3+1], self.index_to_word[0*3+1]),
                (self.index_to_hits[1*3+1], self.index_to_word[1*3+1][:-1]),
                (self.index_to_hits[3*3+1], self.index_to_word[3*3+1][:-1]),
                ]
            count_and_word_list.sort(reverse=True)
            word_f = count_and_word_list[0][1]

            if len(word_f) > 2:
                decl_f, gen_f = g.decl_gen(word_f, "F")
                roots.append((word_f, "F"))
                gen = "F"
            else:
                word_f = "-"

        if mas_count > 0 and mas_case_count >= 2:
            # assume 1st or 2nd declension
            # assume plurals don't change their last letter to α
            count_and_word_list = [
                (self.index_to_hits[0*3], self.index_to_word[0*3][:-1]),
                (self.index_to_hits[2*3], self.index_to_word[2*3][:-1]),
                (self.index_to_hits[3*3], self.index_to_word[3*3][:-1]),

                # note: only works for 2nd declension, remove later if the word is suspitious
                (self.index_to_hits[4*3], self.index_to_word[4*3][:-1]),
                (self.index_to_hits[6*3], self.index_to_word[6*3][:-2]),
                (self.index_to_hits[7*3], self.index_to_word[7*3][:-2]),
                ]
            count_and_word_list.sort(reverse=True)
            word_m = count_and_word_list[0][1]

            # fix: assume plurals don't change their last letter to α
            if g.base_let(word_m[-1]) == 'α':
                count_and_word_list = [
                    (self.index_to_hits[0*3], self.index_to_word[0*3][:-1]),
                    (self.index_to_hits[2*3], self.index_to_word[2*3][:-1]),
                    (self.index_to_hits[3*3], self.index_to_word[3*3][:-1]),
                    ]
                count_and_word_list.sort(reverse=True)
                word_m = count_and_word_list[0][1]

            if len(word_m) > 2:
                decl_m, gen_m = g.decl_gen(word_m, "M")
                roots.append((word_m, "M"))
                gen = "M"
            else:
                word_m = "-"

        if False and (decl_m == "3" or decl_f == "3"):
            roots = []

            word = self.index_to_word[1*3]
            if word.endswith("ος"):
                word = self.index_to_word[1*3][:-2]
                roots.append((word, gen))
            else:
                if mas_count > fem_count:
                    gen = "M"
                    gen_i = 0
                else:
                    gen = "F"
                    gen_i = 1

                x1 = list(zip(_3_mf, self.index_to_word[gen_i::3], range(8)))
                x2 = [(w, e) for e, w, i in x1 if e != '-' and g.base_word(w).endswith(e)]
                x3 = [g.base_word(w[:-len(e)]) for w, e in x2]
                count_and_word_list = [
                    (self.index_to_hits[i*3 + gen_i], w[:-len(e)])
                    for e, w, i
                    in zip(_3_mf, self.index_to_word[gen_i::3], range(8))
                    if e != '-' and g.base_word(w).endswith(e)]
                if count_and_word_list:
                    count_and_word_list.sort(reverse=True)
                    word = count_and_word_list[0][1]
                    if len(word) > 2:
                        decl, gen2 = g.decl_gen(word, gen)
                        if decl == "3":
                            roots.append((word, gen))

        return roots

    def show_match(self, _data, idx):
        calc = _data[0]
        _dbg = _data[1]
        found = self.index_to_word[idx]
        hits = self.index_to_hits[idx]

        if found == "-":
            self._dbg_list.append(("-", _dbg))
            return "      " + calc
        elif calc == found:
            self._match += 1
            self._dbg_list.append(("G", _dbg))
            answer = "(-)" + calc
        elif calc == "":
            answer = "(?)" + found
        else:
            if g.base_word(calc) == g.base_word(found):
                self._soft_error += 1
                answer = "(x)" + calc + "->" + found
                self._dbg_list.append(("W", _dbg))
            else:
                self._hard_error += 1
                answer = "(X)" + calc + "->" + found
                self._dbg_list.append(("E", _dbg))
        return "%3d"%hits + answer

    def show_it(self, word, gen1):
            decl, gen2, data = g.noun_inflect_all(word, gen1)[0]

            if not decl in DO_DECLS:
                return

            print("==================== hits:%d %s:%s %s set-of:%d"%(
                self.all_word_hits, gen1, gen2, word, len(words_and_gen)))

            if self.cwp_to_morph_collision_count:
                print("morph collisions: " + repr(self.cwp_to_morph_collision_count))

            self._dbg_list = []
            self._match = 0
            self._soft_error = 0
            self._hard_error = 0

            max_len = 30
            print("-- %s %s ------------------ decl=%s gen=%s,%s "%(
                word, g.base_word(word), decl, gen1, gen2))
            print("           {1:{0}s} {2:{0}s} {3:{0}s} {4:{0}s}".format(
                max_len+2,
                "__nom__", "__gen__", "__dat__", "__acc__",
                ))
            num_i = 0
            mfn = "MFN".index(gen1)
            for num in ('S', 'P'):
                print("{5}: {1:{0}s} {2:{0}s} {3:{0}s} {4:{0}s}".format(
                    max_len+2,
                    self.show_match(data[num]["N"], OneNoun._idx(num_i, 0, mfn)),
                    self.show_match(data[num]["G"], OneNoun._idx(num_i, 1, mfn)),
                    self.show_match(data[num]["D"], OneNoun._idx(num_i, 2, mfn)),
                    self.show_match(data[num]["A"], OneNoun._idx(num_i, 3, mfn)),

                    num,
                    ))
                num_i += 1

            print("----------\nALL REAL: " + ",".join((
                g.base_word(word)
                for word in (
                    self.index_to_word[OneNoun._idx(sp, ngad, gen1)]
                    for sp in range(2)
                    for ngad in range(4))
                if word != "-")))
            if self._dbg_list and _show_errr_dbg:
                print("----------")
                print("\n".join((x[0] + ": " + repr(x[1]) for x in self._dbg_list if x[0] in _show_errr_dbg)))

            # TODO: this is in a loop, no good
            return (self._match, self._soft_error)


if __name__ == "__main__":

    # create list of OneNoun objects from input files
    art_found = None
    noun_roots = {}
    for word in read_words(sys.argv[1:]):
        if g.base_word(word) in def_art_to_indexes:
            art_found = word
            continue
        if art_found:
            def_art = g.base_word(art_found)
            art_found = None

            root_word, last_syllable = g.split_last_syllable(word)

            if root_word:
                root_word = g.base_word(root_word)
                if not root_word in noun_roots:
                    noun_roots[root_word] = OneNoun(root_word)
                noun_roots[root_word].add_word(def_art, word)

    show = 0
    not_show = 0
    word_collision = 0
    single_word = 0
    wd_match = 0
    wd_soft_error = 0
    wd_hard_error = 0

    noun_roots_list = list(noun_roots.values())
    noun_roots_list.sort(key=lambda r:"%03d%s"%(999-r.all_word_hits, r.root_word))

    for noun_root in noun_roots_list:
        if noun_root.cwp_to_base_collision_count:
            word_collision += 1
            print("==================== hits:%d"%(noun_root.all_word_hits))
            print("word collisions: " + repr(noun_root.cwp_to_base_collision_count))
        elif len(noun_root.unique_words) <= 1:
            single_word += 1
        else:
            # guess masculine and femenine forms of this noun
            words_and_gen = noun_root.derive_roots()
            for word, gen1 in words_and_gen:
                if noun_root.show_it(word, gen1):
                    wd_match += noun_root._match
                    wd_soft_error += noun_root._soft_error
                    wd_hard_error += noun_root._hard_error
                    show += 1
                else:
                    not_show += 1

    print()
    print()
    print("show %d"%(show))
    print("not show %d"%(not_show))
    print("single %d"%(single_word))
    print("word collision %d"%(word_collision))
    print()
    print("word match %d"%(wd_match))
    print("word soft error %d"%(wd_soft_error))
    print("word hard error %d"%(wd_hard_error))

